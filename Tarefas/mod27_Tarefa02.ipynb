{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cabec%CC%A7alho_notebook.png](cabecalho_notebook.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação de Atividade Humana com PCA\n",
    "\n",
    "Vamos trabalhar com a base da demonstração feita em aula, mas vamos explorar um pouco melhor como é o desempenho da árvore variando o número de componentes principais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics            import confusion_matrix\n",
    "from sklearn.metrics            import ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "filename_features = \"base/features.txt\"\n",
    "filename_labels = \"base/activity_labels.txt\"\n",
    "\n",
    "filename_subtrain = \"base/train/subject_train.txt\"\n",
    "filename_xtrain = \"base/train/X_train.txt\"\n",
    "filename_ytrain = \"base/train/y_train.txt\"\n",
    "\n",
    "filename_subtest = \"base/test/subject_test.txt\"\n",
    "ffilename_xtest = \"base/test/X_test.txt\"\n",
    "filename_ytest = \"base/test/y_test.txt\"\n",
    "\n",
    "features = pd.read_csv(filename_features, header=None, names=['nome_var'], sep=\"#\").squeeze()\n",
    "labels = pd.read_csv(filename_labels, delim_whitespace=True, header=None, names=['cod_label', 'label'])\n",
    "\n",
    "subject_train = pd.read_csv(filename_subtrain, header=None, names=['subject_id']).squeeze()\n",
    "X_train = pd.read_csv(filename_xtrain, delim_whitespace=True, header=None, names=features.tolist())\n",
    "y_train = pd.read_csv(filename_ytrain, header=None, names=['cod_label'])\n",
    "\n",
    "subject_test = pd.read_csv(filename_subtest, header=None, names=['subject_id']).squeeze()\n",
    "X_test = pd.read_csv(ffilename_xtest, delim_whitespace=True, header=None, names=features.tolist())\n",
    "y_test = pd.read_csv(filename_ytest, header=None, names=['cod_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA com variáveis padronizadas\n",
    "\n",
    "Reflexão sobre a escala das variáveis:\n",
    "\n",
    "**Variáveis em métricas muito diferentes** podem interferir na análise de componentes principais. Lembra que variância é informação pra nós? Pois bem, tipicamente se há uma variável monetária como salário, vai ter uma ordem de variabilidade bem maior que número de filhos, tempo de emprego ou qualquer variável dummy. Assim, as variáveis de maior variância tendem a \"dominar\" a análise. Nesses casos é comum usar a padronização das variáveis.\n",
    "\n",
    "Faça duas análises de componentes principais para a base do HAR - com e sem padronização e compare:\n",
    "\n",
    "- A variância explicada por componente\n",
    "- A variância explicada acumulada por componente\n",
    "- A variância percentual por componente\n",
    "- A variância percentual acumulada por componente\n",
    "- Quantas componentes você escolheria, em cada caso para explicar 90% da variância?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padroniza(s):\n",
    "    if s.std() > 0:\n",
    "        s = (s - s.mean())/s.std()\n",
    "    return s\n",
    "\n",
    "X_train_pad = pd.DataFrame(X_train).apply(padroniza, axis=0)\n",
    "X_test_pad = pd.DataFrame(X_test).apply(padroniza, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analise_pca(data:pd.DataFrame, porcentagem:float=0.95,text:bool=False) -> tuple[pd.DataFrame, int]:\n",
    "    '''\n",
    "    Função que realiza a análise de componentes principais de um DataFrame\n",
    "\n",
    "    data: DataFrame - DataFrame a ser analisado\n",
    "\n",
    "    porcentagem: float (default=0.95) - Porcentagem da variância que se deseja explicar\n",
    "\n",
    "    return: DataFrame com os componentes principais e a quantidade de componentes necessários para explicar a variância desejada    \n",
    "    '''\n",
    "    pca = PCA()\n",
    "    principalComponents = pca.fit(data)\n",
    "    variancia_explicada             = principalComponents.explained_variance_[:5]\n",
    "    variancia_explicada_acumulada   = principalComponents.explained_variance_.cumsum()[:5]\n",
    "    variancia_percentual            = principalComponents.explained_variance_ratio_[:5]\n",
    "    variancia_percentual_acumulada  = principalComponents.explained_variance_ratio_.cumsum()[:5]\n",
    "    quantidade_componentes = (principalComponents.explained_variance_ratio_.cumsum()<porcentagem).sum()+1\n",
    "\n",
    "    if text:\n",
    "        print('## A seguir amostras da variância dos componentes principais ##\\n')\n",
    "        print(f\"Variância explicada:\\n {variancia_explicada}\\n\")\n",
    "        print(f\"Variância explicada acumulada:\\n {variancia_explicada_acumulada}\\n\")\n",
    "        print(f\"Variância percentual:\\n {variancia_percentual}\\n\")\n",
    "        print(f\"Variância percentual acumulada:\\n {variancia_percentual_acumulada}\\n\")\n",
    "\n",
    "        print(f\"Quantidade de componentes para explicar {porcentagem*100}% da variância: {quantidade_componentes}\")\n",
    "\n",
    "    compontentes = principalComponents.transform(data)\n",
    "    compontentes_df = pd.DataFrame(compontentes,columns=data.columns)\n",
    "    \n",
    "    return compontentes_df,quantidade_componentes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## A seguir amostras da variância dos componentes principais ##\n",
      "\n",
      "Variância explicada:\n",
      " [284.88237655  36.9176163   15.74411031  14.0471749   10.59327893]\n",
      "\n",
      "Variância explicada acumulada:\n",
      " [284.88237655 321.79999285 337.54410316 351.59127806 362.18455699]\n",
      "\n",
      "Variância percentual:\n",
      " [0.50781172 0.0658068  0.02806437 0.02503953 0.01888285]\n",
      "\n",
      "Variância percentual acumulada:\n",
      " [0.50781172 0.57361853 0.60168289 0.62672242 0.64560527]\n",
      "\n",
      "Quantidade de componentes para explicar 90.0% da variância: 63\n"
     ]
    }
   ],
   "source": [
    "## Aplicando a função de análise de PCA para base padronizada\n",
    "df_train_pad, n_componente_pad = analise_pca(X_train_pad,0.90,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## A seguir amostras da variância dos componentes principais ##\n",
      "\n",
      "Variância explicada:\n",
      " [34.82363041  2.73504627  2.29439284  1.04377529  0.943517  ]\n",
      "\n",
      "Variância explicada acumulada:\n",
      " [34.82363041 37.55867667 39.85306951 40.89684481 41.84036181]\n",
      "\n",
      "Variância percentual:\n",
      " [0.6255444  0.04913023 0.04121467 0.01874956 0.0169486 ]\n",
      "\n",
      "Variância percentual acumulada:\n",
      " [0.6255444  0.67467463 0.7158893  0.73463886 0.75158746]\n",
      "\n",
      "Quantidade de componentes para explicar 90.0% da variância: 34\n"
     ]
    }
   ],
   "source": [
    "## Aplicando a função de análise de PCA para base não padronizada\n",
    "df_train, n_componente = analise_pca(X_train,0.90,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árvore com PCA\n",
    "\n",
    "Faça duas uma árvore de decisão com 10 componentes principais - uma com base em dados padronizados e outra sem padronizar. Utilize o ```ccp_alpha=0.001```.\n",
    "\n",
    "Compare a acurácia na base de treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treino_componemtes(\n",
    "        _X_train:pd.DataFrame,\n",
    "        _X_test:pd.DataFrame,\n",
    "        _y_train:pd.DataFrame,\n",
    "        _y_test:pd.DataFrame,\n",
    "        n:int=0):\n",
    "    '''\n",
    "    Função que realiza o treinamento de um modelo de árvore de decisão com base em um número de componentes principais\n",
    "    '''\n",
    "    pca = PCA(n_components=n)\n",
    "    pc_treino = pca.fit_transform(_X_train)\n",
    "    pc_teste = pca.transform(_X_test)\n",
    "    clf = DecisionTreeClassifier(random_state=2360873, ccp_alpha=0.001).fit(pc_treino, _y_train)\n",
    "    print(f'acurácia de treino = {clf.score(pc_treino, _y_train)*100:.2f}%')\n",
    "    print(f'acurácia de teste = {clf.score(pc_teste, _y_test)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acurácia de treino = 85.92%\n",
      "acurácia de teste = 77.74%\n"
     ]
    }
   ],
   "source": [
    "## Treinando o modelo com a base padronizada\n",
    "treino_componemtes(X_train_pad,X_test_pad,y_train,y_test,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acurácia de treino = 89.35%\n",
      "acurácia de teste = 82.32%\n"
     ]
    }
   ],
   "source": [
    "## Treinando o modelo com a base não padronizada\n",
    "treino_componemtes(X_train,X_test,y_train,y_test,10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusão**\n",
    "Os testes com a base `não` padronizada apresentam melhores indicadores de acurácia e quantidade menor de componentes necessários para explicação"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Índice",
   "title_sidebar": "Conteúdo",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
