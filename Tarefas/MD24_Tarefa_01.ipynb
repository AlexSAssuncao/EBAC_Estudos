{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Diferenças entre Random Forest e AdaBoost\n",
    "\n",
    "1.  **Tipo de Ensemble:**\n",
    "    * **Random Forest:** Usa o método de \"bagging\", onde árvores independentes são construídas em paralelo a partir de amostras bootstrap do conjunto de dados.\n",
    "    * **AdaBoost:** Usa o método de \"boosting\", onde modelos fracos são construídos sequencialmente, com cada modelo tentando corrigir os erros do modelo anterior.\n",
    "\n",
    "2.  **Foco nos Erros:**\n",
    "    * **Random Forest:** Foca em reduzir a variância do modelo, criando árvores diversas e não correlacionadas.\n",
    "    * **AdaBoost:** Foca em reduzir o viés do modelo, dando mais peso às amostras que foram classificadas incorretamente pelos modelos anteriores.\n",
    "\n",
    "3.  **Construção das Árvores:**\n",
    "    * **Random Forest:** Cada árvore é construída de forma independente e geralmente é profunda, buscando capturar padrões complexos nos dados.\n",
    "    * **AdaBoost:** Os modelos fracos são construídos sequencialmente e geralmente são rasos (conhecidos como \"stumps\"), focando em aprender padrões simples e corrigir erros gradualmente.\n",
    "\n",
    "4.  **Peso dos Modelos:**\n",
    "    * **Random Forest:** Todas as árvores têm o mesmo peso na votação final.\n",
    "    * **AdaBoost:** Cada modelo fraco tem um peso diferente na votação final, com modelos mais precisos recebendo pesos maiores.\n",
    "\n",
    "5.  **Sensibilidade a Outliers:**\n",
    "    * **Random Forest:** É relativamente robusto a outliers, pois a combinação de várias árvores tende a suavizar o efeito de outliers individuais.\n",
    "    * **AdaBoost:** Pode ser sensível a outliers, pois eles podem receber pesos elevados e influenciar significativamente os modelos subsequentes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.983"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=1000, n_features=4,\n",
    "                           n_informative=2, n_redundant=0,\n",
    "                           random_state=0, shuffle=False)\n",
    "clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(X, y)\n",
    "clf.predict([[0, 0, 0, 0]])\n",
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Hiperparâmetros do AdaBoostClassifier\n",
    "```python\n",
    "AdaBoostClassifier(\n",
    "    estimator=None,\n",
    "    n_estimators=50,\n",
    "    learning_rate=1.0,\n",
    "    algorithm='deprecated',\n",
    "    random_state=None\n",
    ")\n",
    "```\n",
    "\n",
    "* **`estimator=None`**:\n",
    "    * O modelo base (modelo fraco) a ser usado.\n",
    "    * Se `None`, usa `DecisionTreeClassifier` com `max_depth=1` (um \"stump\").\n",
    "    * Você pode especificar outros modelos base, como árvores de decisão mais profundas ou outros classificadores.\n",
    "\n",
    "* **`n_estimators=50`**:\n",
    "    * O número máximo de modelos fracos a serem treinados.\n",
    "    * Aumentar `n_estimators` pode melhorar a precisão, mas também aumentar o tempo de treinamento e o risco de overfitting.\n",
    "\n",
    "* **`learning_rate=1.0`**:\n",
    "    * A contribuição de cada modelo fraco para o modelo final.\n",
    "    * Valores menores de `learning_rate` requerem mais modelos fracos (`n_estimators`) para alcançar um bom desempenho, mas podem melhorar a generalização.\n",
    "\n",
    "* **`algorithm='deprecated'`**:\n",
    "    * Usa o algoritmo SAMME, que é o algoritmo padrão do Adaboost.\n",
    "\n",
    "* **`random_state=None`**:\n",
    "    * Semente para o gerador de números aleatórios.\n",
    "    * Garante a reprodutibilidade dos resultados.\n",
    "    * Definir um valor fixo para `random_state` garante que o modelo seja treinado da mesma forma toda vez que o código for executado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o conjunto de dados Iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir os dados em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=AdaBoostClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;estimator&#x27;: [None], &#x27;learning_rate&#x27;: [0.01, 0.1, 1],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 150, 200, 250, 300, 350, 400,\n",
       "                                          450, 500, 550, 600, 650, 700, 750,\n",
       "                                          800, 850, 900, 950, 1000],\n",
       "                         &#x27;random_state&#x27;: [42]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=AdaBoostClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;estimator&#x27;: [None], &#x27;learning_rate&#x27;: [0.01, 0.1, 1],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 150, 200, 250, 300, 350, 400,\n",
       "                                          450, 500, 550, 600, 650, 700, 750,\n",
       "                                          800, 850, 900, 950, 1000],\n",
       "                         &#x27;random_state&#x27;: [42]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=AdaBoostClassifier(), n_jobs=-1,\n",
       "             param_grid={'estimator': [None], 'learning_rate': [0.01, 0.1, 1],\n",
       "                         'n_estimators': [50, 100, 150, 200, 250, 300, 350, 400,\n",
       "                                          450, 500, 550, 600, 650, 700, 750,\n",
       "                                          800, 850, 900, 950, 1000],\n",
       "                         'random_state': [42]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fazendo o grid search\n",
    "rf = AdaBoostClassifier()\n",
    "params = {\n",
    "    'estimator': [None],\n",
    "    'n_estimators': list(range(50, 1001, 50)),\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(estimator = rf,\n",
    "                        param_grid = params,\n",
    "                        scoring = 'accuracy',\n",
    "                        n_jobs=-1\n",
    "                        )\n",
    "\n",
    "grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(learning_rate=1, n_estimators=100, random_state=42)\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#print os melhores parametros\n",
    "print(grid_rf.best_estimator_)\n",
    "print(grid_rf.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
